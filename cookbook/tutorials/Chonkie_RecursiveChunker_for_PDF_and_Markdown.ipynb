{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W-y43V2AWKlt"
   },
   "source": [
    "# ü¶õ Chonkie: RecursiveChunker for PDF and Markdown Chunking\n",
    "\n",
    "![](https://drive.google.com/uc?export=view&id=1FHBnC4CgPjrvSvoXwJiZqg56I8Ck3SbD)\n",
    "\n",
    "In this notebook, we go over how you can use Chonkie to quickly parse, chunk and run RAG on PDF and Markdown files!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fJ5tsfOeRa7z"
   },
   "source": [
    "## Overview\n",
    "\n",
    "Our entire workflow can be summarized in four simple steps (See table of contents sidebar to jump to a step):\n",
    "\n",
    "1. Convert PDF document to Markdown\n",
    "2. With Chonkie's RecursiveChunker, chunk our markdown document\n",
    "3. Prepare Chunks for RAG\n",
    "4. Use our generated data with an LLM!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pghssFC5Rega"
   },
   "source": [
    "## Acknowledgments\n",
    "\n",
    "We use some awesome services in this notebook, be sure to check them out too:\n",
    "\n",
    "- Chonkie (of course)\n",
    "- Arxiv (for our example PDF file)\n",
    "- Docling (for PDF to Markdown conversion)\n",
    "- Model2Vec (for embeddings)\n",
    "- Vicinity (for indexing)\n",
    "- Together Client (for LLM calls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mv5WRnWmWKlu"
   },
   "source": [
    "## Installs and Imports\n",
    "\n",
    "Installation might take a while, but only the first time!\n",
    "\n",
    "**You may have to restart on your colab instance.** Don't worry, that's completely normal!\n",
    "\n",
    "Just grab a snack and await the CHONK!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "6qv6ArYrWKlu",
    "outputId": "4fe4059e-553d-4ef9-876c-9db252e82ffa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m48.2/48.2 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m51.2/51.2 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m132.3/132.3 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m73.8/73.8 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m147.9/147.9 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m73.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m94.6/94.6 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m76.7/76.7 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m22.4/22.4 MB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m42.1/42.1 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m73.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m72.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m244.3/244.3 kB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m472.8/472.8 kB\u001b[0m \u001b[31m34.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m543.2/543.2 kB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m47.3/47.3 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m73.7/73.7 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m53.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m62.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m46.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m64.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m165.1/165.1 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m422.9/422.9 kB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m969.6/969.6 kB\u001b[0m \u001b[31m50.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m286.6/286.6 kB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m59.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m144.3/144.3 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m272.8/272.8 kB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m119.4/119.4 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install -q chonkie docling model2vec vicinity together rich[jupyter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dODypx_0WKlv"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import List\n",
    "\n",
    "from docling.document_converter import DocumentConverter\n",
    "from google.colab import userdata\n",
    "from model2vec import StaticModel\n",
    "from rich.console import Console\n",
    "from rich.text import Text\n",
    "from together import Together\n",
    "from transformers import AutoTokenizer\n",
    "from vicinity import Backend, Metric, Vicinity\n",
    "\n",
    "from chonkie import RecursiveChunker, RecursiveLevel, RecursiveRules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kMTQUr2df8DD"
   },
   "source": [
    "## Inits and Utils\n",
    "\n",
    "Lets setup everything we need for a smooth chunking experience"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bv297-GIjHIr"
   },
   "source": [
    "### Define utilty functions\n",
    "\n",
    "Just some functions to make the `.pynb` experience better :D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PLEIT2gXgH8z"
   },
   "outputs": [],
   "source": [
    "# Rich text console for better printing\n",
    "console = Console()\n",
    "\n",
    "# A wrapper to pretty print\n",
    "def rprint(text: str, console: Console=console, width: int = 80) -> None:\n",
    "  richtext = Text(text)\n",
    "  console.print(richtext.wrap(console, width=width))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WYIMeyW8ipMH"
   },
   "source": [
    "### Initialize Your Model!\n",
    "\n",
    "Lets initialize the model we will build our application with!\n",
    "\n",
    "Here, we are going to be using Deepseek's R1 model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 336,
     "referenced_widgets": [
      "43d024db3ecd4dc8ac764600313f6c6e",
      "3611101d39794ffaa015057a6d080ccf",
      "a522bda44eca4a58b57e5e65a4ff2477",
      "0595548eaa824d7fa4e9bf2b044872c9",
      "1f8422d0300f48b5ae75816d63ff261f",
      "39eaa50b4d354272b2d9c9f8b201e95d",
      "c30b655de6224ce587aa12f96f3379b6",
      "00fb5de30f7844a3a9e6006a6d1e6b49",
      "60d7f91bd5974da9a607d14dbb38c5ed",
      "ade51100f11c4dbfbb41d68d6513bc3a",
      "5f7bfa61a15a4f80ac217fd558bd55f9",
      "6dc2af962d9b487c9fed218965147458",
      "daf7578a8c204590bb799b0fa618ff03",
      "3d31f1bd989c4946bdd75d58f5074160",
      "142758647bcf403faad865fec178bc3b",
      "d080a5efa9c84c7cbbfbc8ff4843314d",
      "c13d98eaffd840449369d75f0555ce52",
      "147b899639b14e2aaee0e96581353011",
      "90a80459bee24e4487e1db696c92d8ad",
      "3744806ad5ef4ffd9ec4fd97f1befa17",
      "42bacd11289348fe9f3b6421ac26d60b",
      "e853f14f96a5444b8f801e8c5ed02476",
      "cff73eea00554153bb14b3af267352e1",
      "ba35ad19bea142b78218bb8c7d438976",
      "f0fc8514b1a24830b65de57eea9c8045",
      "8ebb3addf8164b778fe9647581faa3d7",
      "3e74d6275dbc424db142c747cd367759",
      "8d7a9f51975441d49d5fcf0752c04d90",
      "86139bfbc95a4687b0a7fe4d3d360471",
      "2222bacfaff1421cb2256695e28eb11e",
      "76f577b7c5214e49a7de48604f6f4160",
      "f3b2307ed8984df497fc806315ad9b0d",
      "7435319d340e4ef0983b1b27e7b93d37",
      "3718a52aa4d94aeb9ef2571812d169fb",
      "839e49a758894f24a44d963f5d277437",
      "f27fc658996240c280074d4415a40aca",
      "15181a70820b4f46ad95fd6307c685e8",
      "6d54795cb21e44b3898d71e11ccb3ff7",
      "6a0665b6095d4867b0fe8d6365e6b022",
      "29489457dc1b44089af57fcd2d7f547c",
      "8f69fb63292f47bd8d01e11591760b30",
      "0f8b4b06d3c448338b2f3cbeb4cd036d",
      "a22aa404b25e4afcbeca3f552e886c8b",
      "f117a1cd5c1847c3bd060ccefaeee2df",
      "a904d439e49b481195bc24d2e136a240",
      "3336df7d5ec748f7a1adc63ad27a9365",
      "c16d7b5356ec4ce4ac8aab8e4d0f1c30",
      "55a1149913464b8080356ccc2cdabe5f",
      "e601051349d144bb9280af6f929a0370",
      "b093418510d24a32bbb33c7a3f9a8982",
      "1a51787d106844b7808918e2170f1b68",
      "08d0c884547941b5921425c9ac5f7d59",
      "61e420284ce24454b256cbfd7c54827f",
      "788f8cc8b15e4b6da7ccd28b8dee4616",
      "e3a6dee2458f47d9b6b544a599586eda",
      "d0192b45f8c5400fb8d7f2c674d799a5",
      "ba810e4ef00148678ed3223b16b05efb",
      "2db7e9c482324c8097ee3ac911bb1c8a",
      "c377bee904544ffa9a23cd580de89857",
      "978d63150d3a4b3bbdf0538505f42145",
      "5deca12537814d9da44c958e419f4dd2",
      "400aeb6c9f734bb2b33d371a6573813f",
      "ec45b2b86eec4b6b81b8a25da528a8b7",
      "fec4de2c8565459ca6db50062994c44c",
      "194a5f60d5204349a4df5de2f5f124cd",
      "9fe69cf76d4a4bf998b161ccac7873de"
     ]
    },
    "collapsed": true,
    "id": "qCuTgkkkWKlw",
    "outputId": "9de1a733-86de-412d-b619-8be0a3dee6a9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43d024db3ecd4dc8ac764600313f6c6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/129M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dc2af962d9b487c9fed218965147458",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/16.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cff73eea00554153bb14b3af267352e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/202 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3718a52aa4d94aeb9ef2571812d169fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.49M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a904d439e49b481195bc24d2e136a240",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/3.58k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0192b45f8c5400fb8d7f2c674d799a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/7.85M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set your Together API key to use Deepseek R1 with it~\n",
    "os.environ['TOGETHER_API_KEY'] = userdata.get('TOGETHER_API_KEY')\n",
    "\n",
    "# Initialise a model2vec model for encoding sentences for retrieval\n",
    "model = StaticModel.from_pretrained(\"minishlab/potion-retrieval-32M\")\n",
    "\n",
    "# Initialise the Together client to call upon Deepseek R1\n",
    "client = Together()\n",
    "\n",
    "# (Optional) Initialise the tokenizer for Deepseek R1\n",
    "# We use this to get token counts at various points in this colab.\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"deepseek-ai/DeepSeek-R1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B2DEzE8IWKlw"
   },
   "source": [
    "## Step 1: Use docling to convert from PDF to Markdown!\n",
    "\n",
    "**Note**: This step can take about 20-30 seconds depending on your PDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "J5xeJIc8WKlw",
    "outputId": "fa09cc85-0116-42b5-b8d5-67ccc7f52c4f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:easyocr.easyocr:Downloading detection model, please wait. This may take several minutes depending upon your network connection.\n",
      "WARNING:easyocr.easyocr:Downloading recognition model, please wait. This may take several minutes depending upon your network connection.\n",
      "/usr/local/lib/python3.11/dist-packages/torch/utils/cpp_extension.py:1964: UserWarning: TORCH_CUDA_ARCH_LIST is not set, all archs for visible cards are included for compilation. \n",
      "If this is not desired, please set os.environ['TORCH_CUDA_ARCH_LIST'].\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Docling can convert any PDF to markdown!\n",
    "converter = DocumentConverter()\n",
    "source = \"https://arxiv.org/pdf/1706.03762\"\n",
    "result = converter.convert(source)\n",
    "text = result.document.export_to_markdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 859
    },
    "collapsed": true,
    "id": "qd9xcOVEWKlw",
    "outputId": "f412854f-cbab-4470-c3ab-f6621adfdeef"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Provided proper attribution is provided, Google hereby grants permission to \n",
       "reproduce the tables and figures in this paper solely for use in journalistic or\n",
       "scholarly works.\n",
       "\n",
       "## Attention Is All You Need\n",
       "\n",
       "Ashish Vaswani ‚àó Google Brain avaswani@google.com\n",
       "\n",
       "Noam Shazeer ‚àó Google Brain noam@google.com\n",
       "\n",
       "Niki Parmar ‚àó Google Research nikip@google.com\n",
       "\n",
       "Jakob Uszkoreit ‚àó Google Research usz@google.com\n",
       "\n",
       "Llion Jones ‚àó Google Research llion@google.com\n",
       "\n",
       "Aidan N. Gomez ‚àó ‚Ä† University of Toronto\n",
       "\n",
       "aidan@cs.toronto.edu\n",
       "\n",
       "≈Åukasz Kaiser Google Brain lukaszkaiser@google.com\n",
       "\n",
       "‚àó\n",
       "\n",
       "Illia Polosukhin ‚àó ‚Ä°\n",
       "\n",
       "illia.polosukhin@gmail.com\n",
       "\n",
       "## Abstract\n",
       "\n",
       "The dominant sequence transduction models are based on complex recurrent or \n",
       "convolutional neural networks that include an encoder and a decoder. The best \n",
       "performing models also connect the encoder and decoder through an attention \n",
       "mechanism. We propose a new simple network architecture, the Transformer, based \n",
       "solely on attention mechanisms, dispensing with recurrence and convolutions \n",
       "entirely. Experiments on two machine translation tasks show these models to be \n",
       "superior in quality while being more parallelizable and requiring significantly \n",
       "less time to train. Our model achieves 28.4 BLEU on the WMT 2014 \n",
       "Englishto-German translation task, improving over the existing best results, \n",
       "including ensembles, by over 2 BLEU. On the WMT 2014 English-to-French \n",
       "translation task, our model establishes a new single-model state-of-the-art BLEU\n",
       "score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the\n",
       "training costs of the best models from the literature. We show that the \n",
       "Transformer generalizes well to other tasks by applying it successfully to \n",
       "English constituency parsing both with large and limited training data.\n",
       "\n",
       "## 1 Introduction\n",
       "\n",
       "Recurrent neural networks, long short-term memory [13] and gated recurrent [7] \n",
       "neural networks in particular, have been firmly established as state of the art \n",
       "approaches in sequence modeling and transduction prob\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Provided proper attribution is provided, Google hereby grants permission to \n",
       "reproduce the tables and figures in this paper solely for use in journalistic or\n",
       "scholarly works.\n",
       "\n",
       "## Attention Is All You Need\n",
       "\n",
       "Ashish Vaswani ‚àó Google Brain avaswani@google.com\n",
       "\n",
       "Noam Shazeer ‚àó Google Brain noam@google.com\n",
       "\n",
       "Niki Parmar ‚àó Google Research nikip@google.com\n",
       "\n",
       "Jakob Uszkoreit ‚àó Google Research usz@google.com\n",
       "\n",
       "Llion Jones ‚àó Google Research llion@google.com\n",
       "\n",
       "Aidan N. Gomez ‚àó ‚Ä† University of Toronto\n",
       "\n",
       "aidan@cs.toronto.edu\n",
       "\n",
       "≈Åukasz Kaiser Google Brain lukaszkaiser@google.com\n",
       "\n",
       "‚àó\n",
       "\n",
       "Illia Polosukhin ‚àó ‚Ä°\n",
       "\n",
       "illia.polosukhin@gmail.com\n",
       "\n",
       "## Abstract\n",
       "\n",
       "The dominant sequence transduction models are based on complex recurrent or \n",
       "convolutional neural networks that include an encoder and a decoder. The best \n",
       "performing models also connect the encoder and decoder through an attention \n",
       "mechanism. We propose a new simple network architecture, the Transformer, based \n",
       "solely on attention mechanisms, dispensing with recurrence and convolutions \n",
       "entirely. Experiments on two machine translation tasks show these models to be \n",
       "superior in quality while being more parallelizable and requiring significantly \n",
       "less time to train. Our model achieves 28.4 BLEU on the WMT 2014 \n",
       "Englishto-German translation task, improving over the existing best results, \n",
       "including ensembles, by over 2 BLEU. On the WMT 2014 English-to-French \n",
       "translation task, our model establishes a new single-model state-of-the-art BLEU\n",
       "score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the\n",
       "training costs of the best models from the literature. We show that the \n",
       "Transformer generalizes well to other tasks by applying it successfully to \n",
       "English constituency parsing both with large and limited training data.\n",
       "\n",
       "## 1 Introduction\n",
       "\n",
       "Recurrent neural networks, long short-term memory [13] and gated recurrent [7] \n",
       "neural networks in particular, have been firmly established as state of the art \n",
       "approaches in sequence modeling and transduction prob\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# @title A quick look at the text we'll be working with~\n",
    "rprint(text[:2000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h-eUVqwAlHbv"
   },
   "source": [
    "### Get the total token counts for this PDF\n",
    "\n",
    "Our example PDF is made up of ~**9,865** tokens! Keep this in mind as we move forward ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "pq4oUNuLWKlx",
    "outputId": "57a921be-cdee-4fdd-e5eb-a3fd2e5e6961"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">This PDF contains: 9865 tokens\n",
       "</pre>\n"
      ],
      "text/plain": [
       "This PDF contains: 9865 tokens\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "total_text_tokens = len(tokenizer.encode(text))\n",
    "rprint(f\"This PDF contains: {total_text_tokens} tokens\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2HZUx_7XWKlx"
   },
   "source": [
    "## Step 2: Chunk your texts w/ Chonkie!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f999ufGNh8Fg"
   },
   "source": [
    "### Initalize your Chunker!\n",
    "For effective markdown chunking, we will be using Chonkie's **recurisve chunker**!\n",
    "\n",
    "With the recursive chunker, we can define custom RecursiveRules that fit our file's structure and format. Since we are working with Markdown files, we will specify rules that help Chonkie understand it's syntax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LgpFvIcmgfeo"
   },
   "outputs": [],
   "source": [
    "rules = RecursiveRules(\n",
    "    levels=[\n",
    "        RecursiveLevel(delimiters=['######', '#####', '####', '###', '##', '#']),\n",
    "        RecursiveLevel(delimiters=['\\n\\n', '\\n', '\\r\\n', '\\r']),\n",
    "        RecursiveLevel(delimiters='.?!;:'),\n",
    "        RecursiveLevel()\n",
    "    ]\n",
    ")\n",
    "chunker = RecursiveChunker(rules=rules, chunk_size=384)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z8SIQmZhLlpI"
   },
   "source": [
    "### Lets Chunk!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fDhSfmHhWKly",
    "outputId": "8291cddf-253f-4217-800c-6375776af676"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of chunks: 57\n"
     ]
    }
   ],
   "source": [
    "# This is all it takes to chunk!\n",
    "chunks = chunker(text)\n",
    "print(f\"Total number of chunks: {len(chunks)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "collapsed": true,
    "id": "SkUdtPdFWKly",
    "outputId": "c7106aa9-757c-4bcc-f456-9aaedf409c4e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Provided proper attribution is provided, Google hereby grants permission to \n",
       "reproduce the tables and figures in this paper solely for use in journalistic or\n",
       "scholarly works.\n",
       "\n",
       "## Attention Is All You Need\n",
       "\n",
       "Ashish Vaswani ‚àó Google Brain avaswani@google.com\n",
       "\n",
       "Noam Shazeer ‚àó Google Brain noam@google.com\n",
       "\n",
       "Niki Parmar ‚àó Google Research nikip@google.com\n",
       "\n",
       "Jakob Uszkoreit ‚àó Google Research usz@google.com\n",
       "\n",
       "Llion Jones ‚àó Google Research llion@google.com\n",
       "\n",
       "Aidan N. Gomez ‚àó ‚Ä† University of Toronto\n",
       "\n",
       "aidan@cs.toronto.edu\n",
       "\n",
       "≈Åukasz Kaiser Google Brain lukaszkaiser@google.com\n",
       "\n",
       "‚àó\n",
       "\n",
       "Illia Polosukhin ‚àó ‚Ä°\n",
       "\n",
       "illia.polosukhin@gmail.com\n",
       "\n",
       "##\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Provided proper attribution is provided, Google hereby grants permission to \n",
       "reproduce the tables and figures in this paper solely for use in journalistic or\n",
       "scholarly works.\n",
       "\n",
       "## Attention Is All You Need\n",
       "\n",
       "Ashish Vaswani ‚àó Google Brain avaswani@google.com\n",
       "\n",
       "Noam Shazeer ‚àó Google Brain noam@google.com\n",
       "\n",
       "Niki Parmar ‚àó Google Research nikip@google.com\n",
       "\n",
       "Jakob Uszkoreit ‚àó Google Research usz@google.com\n",
       "\n",
       "Llion Jones ‚àó Google Research llion@google.com\n",
       "\n",
       "Aidan N. Gomez ‚àó ‚Ä† University of Toronto\n",
       "\n",
       "aidan@cs.toronto.edu\n",
       "\n",
       "≈Åukasz Kaiser Google Brain lukaszkaiser@google.com\n",
       "\n",
       "‚àó\n",
       "\n",
       "Illia Polosukhin ‚àó ‚Ä°\n",
       "\n",
       "illia.polosukhin@gmail.com\n",
       "\n",
       "##\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> Abstract\n",
       "\n",
       "The dominant sequence transduction models are based on complex recurrent or \n",
       "convolutional neural networks that include an encoder and a decoder. The best \n",
       "performing models also connect the encoder and decoder through an attention \n",
       "mechanism. We propose a new simple network architecture, the Transformer, based \n",
       "solely on attention mechanisms, dispensing with recurrence and convolutions \n",
       "entirely. Experiments on two machine translation tasks show these models to be \n",
       "superior in quality while being more parallelizable and requiring significantly \n",
       "less time to train. Our model achieves 28.4 BLEU on the WMT 2014 \n",
       "Englishto-German translation task, improving over the existing best results, \n",
       "including ensembles, by over 2 BLEU. On the WMT 2014 English-to-French \n",
       "translation task, our model establishes a new single-model state-of-the-art BLEU\n",
       "score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the\n",
       "training costs of the best models from the literature. We show that the \n",
       "Transformer generalizes well to other tasks by applying it successfully to \n",
       "English constituency parsing both with large and limited training data.\n",
       "\n",
       "##\n",
       "</pre>\n"
      ],
      "text/plain": [
       " Abstract\n",
       "\n",
       "The dominant sequence transduction models are based on complex recurrent or \n",
       "convolutional neural networks that include an encoder and a decoder. The best \n",
       "performing models also connect the encoder and decoder through an attention \n",
       "mechanism. We propose a new simple network architecture, the Transformer, based \n",
       "solely on attention mechanisms, dispensing with recurrence and convolutions \n",
       "entirely. Experiments on two machine translation tasks show these models to be \n",
       "superior in quality while being more parallelizable and requiring significantly \n",
       "less time to train. Our model achieves 28.4 BLEU on the WMT 2014 \n",
       "Englishto-German translation task, improving over the existing best results, \n",
       "including ensembles, by over 2 BLEU. On the WMT 2014 English-to-French \n",
       "translation task, our model establishes a new single-model state-of-the-art BLEU\n",
       "score of 41.8 after training for 3.5 days on eight GPUs, a small fraction of the\n",
       "training costs of the best models from the literature. We show that the \n",
       "Transformer generalizes well to other tasks by applying it successfully to \n",
       "English constituency parsing both with large and limited training data.\n",
       "\n",
       "##\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> 1 Introduction\n",
       "\n",
       "Recurrent neural networks, long short-term memory [13] and gated recurrent [7] \n",
       "neural networks in particular, have been firmly established as state of the art \n",
       "approaches in sequence modeling and transduction problems such as language \n",
       "modeling and machine translation [35, 2, 5]. Numerous efforts have since \n",
       "continued to push the boundaries of recurrent language models and \n",
       "encoder-decoder architectures [38, 24, 15].\n",
       "\n",
       "Recurrent models typically factor computation along the symbol positions of the \n",
       "input and output sequences. Aligning the positions to steps in computation time,\n",
       "they generate a sequence of hidden states h t , as a function of the previous \n",
       "hidden state h t -1 and the input for position t . This inherently sequential \n",
       "nature precludes parallelization within training examples, which becomes \n",
       "critical at longer sequence lengths, as memory constraints limit batching across\n",
       "examples. Recent work has achieved significant improvements in computational \n",
       "efficiency through factorization tricks [21] and conditional computation [32], \n",
       "while also improving model performance in case of the latter. The fundamental \n",
       "constraint of sequential computation, however, remains.\n",
       "\n",
       "Attention mechanisms have become an integral part of compelling sequence \n",
       "modeling and transduction models in various tasks, allowing modeling of \n",
       "dependencies without regard to their distance in the input or output sequences \n",
       "[2, 19]. In all but a few cases [27], however, such attention mechanisms are \n",
       "used in conjunction with a recurrent network.\n",
       "\n",
       "In this work we propose the Transformer, a model architecture eschewing \n",
       "recurrence and instead relying entirely on an attention mechanism to draw global\n",
       "dependencies between input and output. The Transformer allows for significantly \n",
       "more parallelization and can reach a new state of the art in translation quality\n",
       "after being trained for as little as twelve hours on eight P100 GPUs.\n",
       "\n",
       "##\n",
       "</pre>\n"
      ],
      "text/plain": [
       " 1 Introduction\n",
       "\n",
       "Recurrent neural networks, long short-term memory [13] and gated recurrent [7] \n",
       "neural networks in particular, have been firmly established as state of the art \n",
       "approaches in sequence modeling and transduction problems such as language \n",
       "modeling and machine translation [35, 2, 5]. Numerous efforts have since \n",
       "continued to push the boundaries of recurrent language models and \n",
       "encoder-decoder architectures [38, 24, 15].\n",
       "\n",
       "Recurrent models typically factor computation along the symbol positions of the \n",
       "input and output sequences. Aligning the positions to steps in computation time,\n",
       "they generate a sequence of hidden states h t , as a function of the previous \n",
       "hidden state h t -1 and the input for position t . This inherently sequential \n",
       "nature precludes parallelization within training examples, which becomes \n",
       "critical at longer sequence lengths, as memory constraints limit batching across\n",
       "examples. Recent work has achieved significant improvements in computational \n",
       "efficiency through factorization tricks [21] and conditional computation [32], \n",
       "while also improving model performance in case of the latter. The fundamental \n",
       "constraint of sequential computation, however, remains.\n",
       "\n",
       "Attention mechanisms have become an integral part of compelling sequence \n",
       "modeling and transduction models in various tasks, allowing modeling of \n",
       "dependencies without regard to their distance in the input or output sequences \n",
       "[2, 19]. In all but a few cases [27], however, such attention mechanisms are \n",
       "used in conjunction with a recurrent network.\n",
       "\n",
       "In this work we propose the Transformer, a model architecture eschewing \n",
       "recurrence and instead relying entirely on an attention mechanism to draw global\n",
       "dependencies between input and output. The Transformer allows for significantly \n",
       "more parallelization and can reach a new state of the art in translation quality\n",
       "after being trained for as little as twelve hours on eight P100 GPUs.\n",
       "\n",
       "##\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> 2 Background\n",
       "\n",
       "The goal of reducing sequential computation also forms the foundation of the \n",
       "Extended Neural GPU [16], ByteNet [18] and ConvS2S [9], all of which use \n",
       "convolutional neural networks as basic building block, computing hidden \n",
       "representations in parallel for all input and output positions. In these models,\n",
       "the number of operations required to relate signals from two arbitrary input or \n",
       "output positions grows in the distance between positions, linearly for ConvS2S \n",
       "and logarithmically for ByteNet. This makes it more difficult to learn \n",
       "dependencies between distant positions [12]. In the Transformer this is reduced \n",
       "to a constant number of operations, albeit at the cost of reduced effective \n",
       "resolution due to averaging attention-weighted positions, an effect we \n",
       "counteract with Multi-Head Attention as described in section 3.2.\n",
       "\n",
       "Self-attention, sometimes called intra-attention is an attention mechanism \n",
       "relating different positions of a single sequence in order to compute a \n",
       "representation of the sequence. Self-attention has been used successfully in a \n",
       "variety of tasks including reading comprehension, abstractive summarization, \n",
       "textual entailment and learning task-independent sentence representations [4, \n",
       "27, 28, 22].\n",
       "\n",
       "End-to-end memory networks are based on a recurrent attention mechanism instead \n",
       "of sequencealigned recurrence and have been shown to perform well on \n",
       "simple-language question answering and language modeling tasks [34].\n",
       "\n",
       "To the best of our knowledge, however, the Transformer is the first transduction\n",
       "model relying entirely on self-attention to compute representations of its input\n",
       "and output without using sequencealigned RNNs or convolution. In the following \n",
       "sections, we will describe the Transformer, motivate self-attention and discuss \n",
       "its advantages over models such as [17, 18] and [9].\n",
       "\n",
       "##\n",
       "</pre>\n"
      ],
      "text/plain": [
       " 2 Background\n",
       "\n",
       "The goal of reducing sequential computation also forms the foundation of the \n",
       "Extended Neural GPU [16], ByteNet [18] and ConvS2S [9], all of which use \n",
       "convolutional neural networks as basic building block, computing hidden \n",
       "representations in parallel for all input and output positions. In these models,\n",
       "the number of operations required to relate signals from two arbitrary input or \n",
       "output positions grows in the distance between positions, linearly for ConvS2S \n",
       "and logarithmically for ByteNet. This makes it more difficult to learn \n",
       "dependencies between distant positions [12]. In the Transformer this is reduced \n",
       "to a constant number of operations, albeit at the cost of reduced effective \n",
       "resolution due to averaging attention-weighted positions, an effect we \n",
       "counteract with Multi-Head Attention as described in section 3.2.\n",
       "\n",
       "Self-attention, sometimes called intra-attention is an attention mechanism \n",
       "relating different positions of a single sequence in order to compute a \n",
       "representation of the sequence. Self-attention has been used successfully in a \n",
       "variety of tasks including reading comprehension, abstractive summarization, \n",
       "textual entailment and learning task-independent sentence representations [4, \n",
       "27, 28, 22].\n",
       "\n",
       "End-to-end memory networks are based on a recurrent attention mechanism instead \n",
       "of sequencealigned recurrence and have been shown to perform well on \n",
       "simple-language question answering and language modeling tasks [34].\n",
       "\n",
       "To the best of our knowledge, however, the Transformer is the first transduction\n",
       "model relying entirely on self-attention to compute representations of its input\n",
       "and output without using sequencealigned RNNs or convolution. In the following \n",
       "sections, we will describe the Transformer, motivate self-attention and discuss \n",
       "its advantages over models such as [17, 18] and [9].\n",
       "\n",
       "##\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# @title A quick look at our chunks~\n",
    "for chunk in chunks[:4]:\n",
    "  rprint(chunk.text)\n",
    "  print('-'*80, '\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WmY3lMVxWKly"
   },
   "source": [
    "## Step 3: Retrieval Augmented Generation!\n",
    "\n",
    "Let's setup RAG to get our chunks when needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UzyJMtLUWKly"
   },
   "source": [
    "### Step 3.1: Get the embeddings for each of the chunks!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-VvbKceEWKly",
    "outputId": "b77d9bde-16f5-4458-95d9-88b27ce9b14f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(57, 512)\n"
     ]
    }
   ],
   "source": [
    "items = [chunk.text for chunk in chunks]\n",
    "vectors = model.encode(items)\n",
    "print(vectors.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1EaYeq7IWKlz"
   },
   "source": [
    "### Step 3.2: Create an index with the chunks and embeddings for retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KdaHRMi3WKlz"
   },
   "outputs": [],
   "source": [
    "# Initialize the Vicinity instance (using basic backend and cosine metric)\n",
    "vicinity = Vicinity.from_vectors_and_items(\n",
    "    vectors=vectors,\n",
    "    items=items,\n",
    "    backend_type=Backend.BASIC,\n",
    "    metric=Metric.COSINE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6SJjXWZNWKlz"
   },
   "source": [
    "### Step 3.3: Pack it all together in a single retrieval function!\n",
    "\n",
    "Given a query, retrieve all relevant embeddings~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2AYHiaWPteUO"
   },
   "outputs": [],
   "source": [
    "def get_embeddings(query: str):\n",
    "  query_vector = model.encode(query)\n",
    "  results = vicinity.query(query_vector, k=4)\n",
    "  return [x[0] for x in results[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_slMghH3tt_3"
   },
   "source": [
    "### (Optional) Step 3.4: Test our function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "PLENTTzMWKlz",
    "outputId": "95d0e247-9e74-4f26-8f89-700cfe0c4572"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> Attention Visualizations Input-Input Layer5\n",
       "\n",
       "Figure 3: An example of the attention mechanism following long-distance \n",
       "dependencies in the encoder self-attention in layer 5 of 6. Many of the \n",
       "attention heads attend to a distant dependency of the verb 'making', completing \n",
       "the phrase 'making...more difficult'. Attentions here shown only for the word \n",
       "'making'. Different colors represent different heads. Best viewed in color.\n",
       "\n",
       "&lt;!-- image --&gt;\n",
       "\n",
       "Input-Input Layer5\n",
       "\n",
       "Figure 4: Two attention heads, also in layer 5 of 6, apparently involved in \n",
       "anaphora resolution. Top: Full attentions for head 5. Bottom: Isolated \n",
       "attentions from just the word 'its' for attention heads 5 and 6. Note that the \n",
       "attentions are very sharp for this word.\n",
       "\n",
       "&lt;!-- image --&gt;\n",
       "\n",
       "Input-Input Layer5\n",
       "\n",
       "Figure 5: Many of the attention heads exhibit behaviour that seems related to \n",
       "the structure of the sentence. We give two such examples above, from two \n",
       "different heads from the encoder self-attention at layer 5 of 6. The heads \n",
       "clearly learned to perform different tasks.\n",
       "\n",
       "&lt;!-- image --&gt;\n",
       "</pre>\n"
      ],
      "text/plain": [
       " Attention Visualizations Input-Input Layer5\n",
       "\n",
       "Figure 3: An example of the attention mechanism following long-distance \n",
       "dependencies in the encoder self-attention in layer 5 of 6. Many of the \n",
       "attention heads attend to a distant dependency of the verb 'making', completing \n",
       "the phrase 'making...more difficult'. Attentions here shown only for the word \n",
       "'making'. Different colors represent different heads. Best viewed in color.\n",
       "\n",
       "<!-- image -->\n",
       "\n",
       "Input-Input Layer5\n",
       "\n",
       "Figure 4: Two attention heads, also in layer 5 of 6, apparently involved in \n",
       "anaphora resolution. Top: Full attentions for head 5. Bottom: Isolated \n",
       "attentions from just the word 'its' for attention heads 5 and 6. Note that the \n",
       "attentions are very sharp for this word.\n",
       "\n",
       "<!-- image -->\n",
       "\n",
       "Input-Input Layer5\n",
       "\n",
       "Figure 5: Many of the attention heads exhibit behaviour that seems related to \n",
       "the structure of the sentence. We give two such examples above, from two \n",
       "different heads from the encoder self-attention at layer 5 of 6. The heads \n",
       "clearly learned to perform different tasks.\n",
       "\n",
       "<!-- image -->\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> 2 Background\n",
       "\n",
       "The goal of reducing sequential computation also forms the foundation of the \n",
       "Extended Neural GPU [16], ByteNet [18] and ConvS2S [9], all of which use \n",
       "convolutional neural networks as basic building block, computing hidden \n",
       "representations in parallel for all input and output positions. In these models,\n",
       "the number of operations required to relate signals from two arbitrary input or \n",
       "output positions grows in the distance between positions, linearly for ConvS2S \n",
       "and logarithmically for ByteNet. This makes it more difficult to learn \n",
       "dependencies between distant positions [12]. In the Transformer this is reduced \n",
       "to a constant number of operations, albeit at the cost of reduced effective \n",
       "resolution due to averaging attention-weighted positions, an effect we \n",
       "counteract with Multi-Head Attention as described in section 3.2.\n",
       "\n",
       "Self-attention, sometimes called intra-attention is an attention mechanism \n",
       "relating different positions of a single sequence in order to compute a \n",
       "representation of the sequence. Self-attention has been used successfully in a \n",
       "variety of tasks including reading comprehension, abstractive summarization, \n",
       "textual entailment and learning task-independent sentence representations [4, \n",
       "27, 28, 22].\n",
       "\n",
       "End-to-end memory networks are based on a recurrent attention mechanism instead \n",
       "of sequencealigned recurrence and have been shown to perform well on \n",
       "simple-language question answering and language modeling tasks [34].\n",
       "\n",
       "To the best of our knowledge, however, the Transformer is the first transduction\n",
       "model relying entirely on self-attention to compute representations of its input\n",
       "and output without using sequencealigned RNNs or convolution. In the following \n",
       "sections, we will describe the Transformer, motivate self-attention and discuss \n",
       "its advantages over models such as [17, 18] and [9].\n",
       "\n",
       "##\n",
       "</pre>\n"
      ],
      "text/plain": [
       " 2 Background\n",
       "\n",
       "The goal of reducing sequential computation also forms the foundation of the \n",
       "Extended Neural GPU [16], ByteNet [18] and ConvS2S [9], all of which use \n",
       "convolutional neural networks as basic building block, computing hidden \n",
       "representations in parallel for all input and output positions. In these models,\n",
       "the number of operations required to relate signals from two arbitrary input or \n",
       "output positions grows in the distance between positions, linearly for ConvS2S \n",
       "and logarithmically for ByteNet. This makes it more difficult to learn \n",
       "dependencies between distant positions [12]. In the Transformer this is reduced \n",
       "to a constant number of operations, albeit at the cost of reduced effective \n",
       "resolution due to averaging attention-weighted positions, an effect we \n",
       "counteract with Multi-Head Attention as described in section 3.2.\n",
       "\n",
       "Self-attention, sometimes called intra-attention is an attention mechanism \n",
       "relating different positions of a single sequence in order to compute a \n",
       "representation of the sequence. Self-attention has been used successfully in a \n",
       "variety of tasks including reading comprehension, abstractive summarization, \n",
       "textual entailment and learning task-independent sentence representations [4, \n",
       "27, 28, 22].\n",
       "\n",
       "End-to-end memory networks are based on a recurrent attention mechanism instead \n",
       "of sequencealigned recurrence and have been shown to perform well on \n",
       "simple-language question answering and language modeling tasks [34].\n",
       "\n",
       "To the best of our knowledge, however, the Transformer is the first transduction\n",
       "model relying entirely on self-attention to compute representations of its input\n",
       "and output without using sequencealigned RNNs or convolution. In the following \n",
       "sections, we will describe the Transformer, motivate self-attention and discuss \n",
       "its advantages over models such as [17, 18] and [9].\n",
       "\n",
       "##\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> Scaled Dot-Product Attention\n",
       "\n",
       "&lt;!-- image --&gt;\n",
       "\n",
       "Figure 2: (left) Scaled Dot-Product Attention. (right) Multi-Head Attention \n",
       "consists of several attention layers running in parallel.\n",
       "\n",
       "&lt;!-- image --&gt;\n",
       "\n",
       "of the values, where the weight assigned to each value is computed by a \n",
       "compatibility function of the query with the corresponding key.\n",
       "\n",
       "##\n",
       "</pre>\n"
      ],
      "text/plain": [
       " Scaled Dot-Product Attention\n",
       "\n",
       "<!-- image -->\n",
       "\n",
       "Figure 2: (left) Scaled Dot-Product Attention. (right) Multi-Head Attention \n",
       "consists of several attention layers running in parallel.\n",
       "\n",
       "<!-- image -->\n",
       "\n",
       "of the values, where the weight assigned to each value is computed by a \n",
       "compatibility function of the query with the corresponding key.\n",
       "\n",
       "##\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"> 3.2.2 Multi-Head Attention\n",
       "\n",
       "Instead of performing a single attention function with d model-dimensional keys,\n",
       "values and queries, we found it beneficial to linearly project the queries, keys\n",
       "and values h times with different, learned linear projections to d k , d k and d\n",
       "v dimensions, respectively. On each of these projected versions of queries, keys\n",
       "and values we then perform the attention function in parallel, yielding d v \n",
       "-dimensional\n",
       "\n",
       "output values. These are concatenated and once again projected, resulting in the\n",
       "final values, as depicted in Figure 2.\n",
       "\n",
       "Multi-head attention allows the model to jointly attend to information from \n",
       "different representation subspaces at different positions. With a single \n",
       "attention head, averaging inhibits this.\n",
       "\n",
       "&lt;!-- formula-not-decoded --&gt;\n",
       "\n",
       "&lt;!-- formula-not-decoded --&gt;\n",
       "\n",
       "Where the projections are parameter matrices W Q i ‚àà R d model √ó d k , W K i ‚àà R\n",
       "d model √ó d k , W V i ‚àà R d model √ó d v and W O ‚àà R hd v √ó d model .\n",
       "\n",
       "In this work we employ h = 8 parallel attention layers, or heads. For each of \n",
       "these we use d k = d v = d model /h = 64 . Due to the reduced dimension of each \n",
       "head, the total computational cost is similar to that of single-head attention \n",
       "with full dimensionality.\n",
       "\n",
       "##\n",
       "</pre>\n"
      ],
      "text/plain": [
       " 3.2.2 Multi-Head Attention\n",
       "\n",
       "Instead of performing a single attention function with d model-dimensional keys,\n",
       "values and queries, we found it beneficial to linearly project the queries, keys\n",
       "and values h times with different, learned linear projections to d k , d k and d\n",
       "v dimensions, respectively. On each of these projected versions of queries, keys\n",
       "and values we then perform the attention function in parallel, yielding d v \n",
       "-dimensional\n",
       "\n",
       "output values. These are concatenated and once again projected, resulting in the\n",
       "final values, as depicted in Figure 2.\n",
       "\n",
       "Multi-head attention allows the model to jointly attend to information from \n",
       "different representation subspaces at different positions. With a single \n",
       "attention head, averaging inhibits this.\n",
       "\n",
       "<!-- formula-not-decoded -->\n",
       "\n",
       "<!-- formula-not-decoded -->\n",
       "\n",
       "Where the projections are parameter matrices W Q i ‚àà R d model √ó d k , W K i ‚àà R\n",
       "d model √ó d k , W V i ‚àà R d model √ó d v and W O ‚àà R hd v √ó d model .\n",
       "\n",
       "In this work we employ h = 8 parallel attention layers, or heads. For each of \n",
       "these we use d k = d v = d model /h = 64 . Due to the reduced dimension of each \n",
       "head, the total computational cost is similar to that of single-head attention \n",
       "with full dimensionality.\n",
       "\n",
       "##\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------------- \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"What is a Multi-Head Self Attention?\"\n",
    "retrieved_chunks = get_embeddings(query)\n",
    "\n",
    "for chunk in retrieved_chunks:\n",
    "  rprint(chunk)\n",
    "  print('-'*80, '\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YPy7bqrEWKl0"
   },
   "source": [
    "## Step 4: Lets build our LLM Application!\n",
    "\n",
    "Our data is ready! Let's setup our LLM application to answer user queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CRjaTG2oR7eC"
   },
   "outputs": [],
   "source": [
    "# A simple function to make LLM prompts with chunks\n",
    "def create_prompt(chunks: List[str], query: str) -> str:\n",
    "  prompt_template = \"\"\"<instructions>\n",
    "  Based on the provided contexts, answer the given question to the best of your ability. Remember to also add citations at appropriate points in the format of square brackets like [1][2][3], especially at sentence or paragraph endings.\n",
    "  You will be given 4 passages in the context, marked with a label 'Doc [1]:' to denote the passage number. Use that number for citations. Answer only from the given context, and if there's no appropriate context, reply \"No relevant context found!\".\n",
    "  </instructions>\n",
    "\n",
    "  <context>\n",
    "  {context}\n",
    "  </context>\n",
    "\n",
    "  <query>\n",
    "  {query}\n",
    "  </query>\n",
    "  \"\"\"\n",
    "  context = \"\\n\\n\".join([f\"Doc {i+1}: {chunk}\" for i, chunk in enumerate(chunks)])\n",
    "  prompt = prompt_template.format(context=context, query=query)\n",
    "  return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k40GjsL2WKl0"
   },
   "outputs": [],
   "source": [
    "# Prompt to use\n",
    "query = \"What is a Multi-Head Self Attention?\"\n",
    "retrieved_chunks = get_embeddings(query)\n",
    "prompt = create_prompt(retrieved_chunks, query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 314
    },
    "id": "BnY1fZzEWKl0",
    "outputId": "6702fd05-ffff-456d-eac9-1ee6e0e8c098"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "\n",
       "Multi-Head Self Attention is a mechanism in the Transformer model that enables \n",
       "the system to jointly process information from different representation \n",
       "subspaces at various positions in parallel. Instead of using a single attention \n",
       "function, it linearly projects the queries, keys, and values multiple times \n",
       "(using distinct learned projections for each \"head\") [4]. Each head \n",
       "independently performs the scaled dot-product attention function on these \n",
       "projected inputs, generating outputs that are concatenated and reprojected to \n",
       "form the final result [4][3]. \n",
       "\n",
       "This approach allows the model to capture diverse dependencies, such as \n",
       "long-distance syntactic relationships (e.g., verb-phrase completion in Figure 3 \n",
       "of Doc 1) or anaphora resolution (e.g., tracking \"its\" in Figure 4 of Doc 1) \n",
       "[1]. By using multiple heads (typically 8), the model avoids the limitations of \n",
       "single-head attention, where averaging might suppress nuanced patterns across \n",
       "different positional or contextual subspaces [4]. The computational cost remains\n",
       "manageable due to reduced dimensionality per head (e.g., 64 dimensions per head \n",
       "when using 8 heads) [4].\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\n",
       "Multi-Head Self Attention is a mechanism in the Transformer model that enables \n",
       "the system to jointly process information from different representation \n",
       "subspaces at various positions in parallel. Instead of using a single attention \n",
       "function, it linearly projects the queries, keys, and values multiple times \n",
       "(using distinct learned projections for each \"head\") [4]. Each head \n",
       "independently performs the scaled dot-product attention function on these \n",
       "projected inputs, generating outputs that are concatenated and reprojected to \n",
       "form the final result [4][3]. \n",
       "\n",
       "This approach allows the model to capture diverse dependencies, such as \n",
       "long-distance syntactic relationships (e.g., verb-phrase completion in Figure 3 \n",
       "of Doc 1) or anaphora resolution (e.g., tracking \"its\" in Figure 4 of Doc 1) \n",
       "[1]. By using multiple heads (typically 8), the model avoids the limitations of \n",
       "single-head attention, where averaging might suppress nuanced patterns across \n",
       "different positional or contextual subspaces [4]. The computational cost remains\n",
       "manageable due to reduced dimensionality per head (e.g., 64 dimensions per head \n",
       "when using 8 heads) [4].\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"deepseek-ai/DeepSeek-R1\",\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    ")\n",
    "# Print the final response without the thinking tokens\n",
    "answer = response.choices[0].message.content.split(\"</think>\")[-1]\n",
    "rprint(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jS9byevRO3KQ"
   },
   "source": [
    "### Wow, the model works great! And how many tokens did we use?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "JciPBJ29WKl1",
    "outputId": "122b0371-b7be-4a0f-cc8b-76e5b8256d18"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">This prompt contains: 1069 tokens\n",
       "</pre>\n"
      ],
      "text/plain": [
       "This prompt contains: 1069 tokens\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt_tokens = len(tokenizer.encode(prompt))\n",
    "rprint(f\"This prompt contains: {prompt_tokens} tokens\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K9A5B81FPFnq"
   },
   "source": [
    "**1,069 tokens!** Rememeber from earlier--without chunking we'd have used 9,865 tokens!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cyaRx7JPWKl1"
   },
   "source": [
    "## Conclusions\n",
    "\n",
    "We got a great answer back from our model, while saving about **~8,800 input tokens**! Chonkie is one efficient hippo üöÄ\n",
    "\n",
    "Hope you found this notebook useful! If you want to learn more about Chonkie, check our [GitHub](https://github.com/chonkie-ai/chonkie), [Twitter](https://x.com/ChonkieAI), and [Bluesky](https://bsky.app/profile/chonkieai.bsky.social)!\n",
    "\n",
    "If you have any questions about anything we showed us here, reach us at `support@chonkie.ai` or on our [Discord](https://discord.gg/6V5pqvqsCY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wy7Sa4KMaUss"
   },
   "source": [
    "# Fin\n",
    "\n",
    "Happy Chonking! ü¶õ‚ú®"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "00fb5de30f7844a3a9e6006a6d1e6b49": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0595548eaa824d7fa4e9bf2b044872c9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ade51100f11c4dbfbb41d68d6513bc3a",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_5f7bfa61a15a4f80ac217fd558bd55f9",
      "value": "‚Äá129M/129M‚Äá[00:03&lt;00:00,‚Äá40.0MB/s]"
     }
    },
    "08d0c884547941b5921425c9ac5f7d59": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0f8b4b06d3c448338b2f3cbeb4cd036d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "142758647bcf403faad865fec178bc3b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_42bacd11289348fe9f3b6421ac26d60b",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_e853f14f96a5444b8f801e8c5ed02476",
      "value": "‚Äá16.7k/16.7k‚Äá[00:00&lt;00:00,‚Äá1.22MB/s]"
     }
    },
    "147b899639b14e2aaee0e96581353011": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "15181a70820b4f46ad95fd6307c685e8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a22aa404b25e4afcbeca3f552e886c8b",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_f117a1cd5c1847c3bd060ccefaeee2df",
      "value": "‚Äá1.49M/1.49M‚Äá[00:01&lt;00:00,‚Äá1.03MB/s]"
     }
    },
    "194a5f60d5204349a4df5de2f5f124cd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1a51787d106844b7808918e2170f1b68": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1f8422d0300f48b5ae75816d63ff261f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2222bacfaff1421cb2256695e28eb11e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "29489457dc1b44089af57fcd2d7f547c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2db7e9c482324c8097ee3ac911bb1c8a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ec45b2b86eec4b6b81b8a25da528a8b7",
      "max": 7847602,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_fec4de2c8565459ca6db50062994c44c",
      "value": 7847602
     }
    },
    "3336df7d5ec748f7a1adc63ad27a9365": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b093418510d24a32bbb33c7a3f9a8982",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_1a51787d106844b7808918e2170f1b68",
      "value": "tokenizer_config.json:‚Äá100%"
     }
    },
    "3611101d39794ffaa015057a6d080ccf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_39eaa50b4d354272b2d9c9f8b201e95d",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_c30b655de6224ce587aa12f96f3379b6",
      "value": "model.safetensors:‚Äá100%"
     }
    },
    "3718a52aa4d94aeb9ef2571812d169fb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_839e49a758894f24a44d963f5d277437",
       "IPY_MODEL_f27fc658996240c280074d4415a40aca",
       "IPY_MODEL_15181a70820b4f46ad95fd6307c685e8"
      ],
      "layout": "IPY_MODEL_6d54795cb21e44b3898d71e11ccb3ff7"
     }
    },
    "3744806ad5ef4ffd9ec4fd97f1befa17": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "39eaa50b4d354272b2d9c9f8b201e95d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3d31f1bd989c4946bdd75d58f5074160": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_90a80459bee24e4487e1db696c92d8ad",
      "max": 16673,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3744806ad5ef4ffd9ec4fd97f1befa17",
      "value": 16673
     }
    },
    "3e74d6275dbc424db142c747cd367759": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "400aeb6c9f734bb2b33d371a6573813f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "42bacd11289348fe9f3b6421ac26d60b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "43d024db3ecd4dc8ac764600313f6c6e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3611101d39794ffaa015057a6d080ccf",
       "IPY_MODEL_a522bda44eca4a58b57e5e65a4ff2477",
       "IPY_MODEL_0595548eaa824d7fa4e9bf2b044872c9"
      ],
      "layout": "IPY_MODEL_1f8422d0300f48b5ae75816d63ff261f"
     }
    },
    "55a1149913464b8080356ccc2cdabe5f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_788f8cc8b15e4b6da7ccd28b8dee4616",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_e3a6dee2458f47d9b6b544a599586eda",
      "value": "‚Äá3.58k/3.58k‚Äá[00:00&lt;00:00,‚Äá169kB/s]"
     }
    },
    "5deca12537814d9da44c958e419f4dd2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5f7bfa61a15a4f80ac217fd558bd55f9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "60d7f91bd5974da9a607d14dbb38c5ed": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "61e420284ce24454b256cbfd7c54827f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "6a0665b6095d4867b0fe8d6365e6b022": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6d54795cb21e44b3898d71e11ccb3ff7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6dc2af962d9b487c9fed218965147458": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_daf7578a8c204590bb799b0fa618ff03",
       "IPY_MODEL_3d31f1bd989c4946bdd75d58f5074160",
       "IPY_MODEL_142758647bcf403faad865fec178bc3b"
      ],
      "layout": "IPY_MODEL_d080a5efa9c84c7cbbfbc8ff4843314d"
     }
    },
    "7435319d340e4ef0983b1b27e7b93d37": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "76f577b7c5214e49a7de48604f6f4160": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "788f8cc8b15e4b6da7ccd28b8dee4616": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "839e49a758894f24a44d963f5d277437": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6a0665b6095d4867b0fe8d6365e6b022",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_29489457dc1b44089af57fcd2d7f547c",
      "value": "tokenizer.json:‚Äá100%"
     }
    },
    "86139bfbc95a4687b0a7fe4d3d360471": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "8d7a9f51975441d49d5fcf0752c04d90": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8ebb3addf8164b778fe9647581faa3d7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f3b2307ed8984df497fc806315ad9b0d",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_7435319d340e4ef0983b1b27e7b93d37",
      "value": "‚Äá202/202‚Äá[00:00&lt;00:00,‚Äá16.6kB/s]"
     }
    },
    "8f69fb63292f47bd8d01e11591760b30": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "90a80459bee24e4487e1db696c92d8ad": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "978d63150d3a4b3bbdf0538505f42145": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9fe69cf76d4a4bf998b161ccac7873de": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a22aa404b25e4afcbeca3f552e886c8b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a522bda44eca4a58b57e5e65a4ff2477": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_00fb5de30f7844a3a9e6006a6d1e6b49",
      "max": 129210456,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_60d7f91bd5974da9a607d14dbb38c5ed",
      "value": 129210456
     }
    },
    "a904d439e49b481195bc24d2e136a240": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3336df7d5ec748f7a1adc63ad27a9365",
       "IPY_MODEL_c16d7b5356ec4ce4ac8aab8e4d0f1c30",
       "IPY_MODEL_55a1149913464b8080356ccc2cdabe5f"
      ],
      "layout": "IPY_MODEL_e601051349d144bb9280af6f929a0370"
     }
    },
    "ade51100f11c4dbfbb41d68d6513bc3a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b093418510d24a32bbb33c7a3f9a8982": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ba35ad19bea142b78218bb8c7d438976": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8d7a9f51975441d49d5fcf0752c04d90",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_86139bfbc95a4687b0a7fe4d3d360471",
      "value": "config.json:‚Äá100%"
     }
    },
    "ba810e4ef00148678ed3223b16b05efb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5deca12537814d9da44c958e419f4dd2",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_400aeb6c9f734bb2b33d371a6573813f",
      "value": "tokenizer.json:‚Äá100%"
     }
    },
    "c13d98eaffd840449369d75f0555ce52": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c16d7b5356ec4ce4ac8aab8e4d0f1c30": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_08d0c884547941b5921425c9ac5f7d59",
      "max": 3584,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_61e420284ce24454b256cbfd7c54827f",
      "value": 3584
     }
    },
    "c30b655de6224ce587aa12f96f3379b6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c377bee904544ffa9a23cd580de89857": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_194a5f60d5204349a4df5de2f5f124cd",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_9fe69cf76d4a4bf998b161ccac7873de",
      "value": "‚Äá7.85M/7.85M‚Äá[00:04&lt;00:00,‚Äá1.85MB/s]"
     }
    },
    "cff73eea00554153bb14b3af267352e1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ba35ad19bea142b78218bb8c7d438976",
       "IPY_MODEL_f0fc8514b1a24830b65de57eea9c8045",
       "IPY_MODEL_8ebb3addf8164b778fe9647581faa3d7"
      ],
      "layout": "IPY_MODEL_3e74d6275dbc424db142c747cd367759"
     }
    },
    "d0192b45f8c5400fb8d7f2c674d799a5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ba810e4ef00148678ed3223b16b05efb",
       "IPY_MODEL_2db7e9c482324c8097ee3ac911bb1c8a",
       "IPY_MODEL_c377bee904544ffa9a23cd580de89857"
      ],
      "layout": "IPY_MODEL_978d63150d3a4b3bbdf0538505f42145"
     }
    },
    "d080a5efa9c84c7cbbfbc8ff4843314d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "daf7578a8c204590bb799b0fa618ff03": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c13d98eaffd840449369d75f0555ce52",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_147b899639b14e2aaee0e96581353011",
      "value": "README.md:‚Äá100%"
     }
    },
    "e3a6dee2458f47d9b6b544a599586eda": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e601051349d144bb9280af6f929a0370": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e853f14f96a5444b8f801e8c5ed02476": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ec45b2b86eec4b6b81b8a25da528a8b7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f0fc8514b1a24830b65de57eea9c8045": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2222bacfaff1421cb2256695e28eb11e",
      "max": 202,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_76f577b7c5214e49a7de48604f6f4160",
      "value": 202
     }
    },
    "f117a1cd5c1847c3bd060ccefaeee2df": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f27fc658996240c280074d4415a40aca": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8f69fb63292f47bd8d01e11591760b30",
      "max": 1493150,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0f8b4b06d3c448338b2f3cbeb4cd036d",
      "value": 1493150
     }
    },
    "f3b2307ed8984df497fc806315ad9b0d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fec4de2c8565459ca6db50062994c44c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}